

# ğŸš€ Real-Time File Processing using AWS Lambda

This project implements a **serverless, event-driven pipeline** for processing files in **real-time** using **AWS S3, SQS, Lambda, and DynamoDB**.
A Windows service monitors a folder for incoming files and automatically uploads them to an S3 bucket.
Each upload triggers an automated workflow that cleans, transforms, and stores the processed data.

---

## ğŸ“Œ **Architecture Overview**

<img src="real time file processing.png" width="850"/>

---

## ğŸ§© **How It Works**

### **1ï¸âƒ£ Windows Folder Watcher (Source Layer)**

* A lightweight **Windows background service** monitors a folder.
* Whenever a new file arrives, it automatically uploads the file to **S3 (Raw Zone)**.

### **2ï¸âƒ£ S3 Bucket (Storage Layer)**

* Stores incoming raw files.
* Triggers **S3 Event Notifications** with file metadata (key, path, size, timestamp).

### **3ï¸âƒ£ SQS Queue (Event Layer)**

* Receives metadata from S3.
* Delivers messages reliably and asynchronously to Lambda.

### **4ï¸âƒ£ AWS Lambda (Processing Layer)**

Lambda is triggered for **each incoming SQS message**.
It performs:

* ğŸ“¥ Fetch object from S3
* ğŸ”„ Parse & transform the file
* ğŸ“¤ Write cleaned records into **DynamoDB**

### **5ï¸âƒ£ DynamoDB (Database Layer)**

* Stores the final structured data
* Supports fast lookup & scalable ingestion

### **6ï¸âƒ£ IAM + CloudWatch (Security & Monitoring)**

* IAM policies allow secure communication between services
* CloudWatch tracks logs, metrics
* SNS sends error/alert notifications

---

## ğŸ—‚ï¸ **Project Structure**

```
ğŸ“¦ Real-Time File Processing
â”œâ”€â”€ lambda code.py          # AWS Lambda processing script
â”œâ”€â”€ real time file processing.png   # Architecture diagram
â””â”€â”€ README.md               # Documentation
```

---

## ğŸ”§ **Technologies Used**

| Service             | Purpose                      |
| ------------------- | ---------------------------- |
| ğŸ–¥ï¸ Windows Service | Folder monitoring            |
| ğŸª£ Amazon S3        | Raw file storage             |
| ğŸ“© Amazon SQS       | Event messaging              |
| Î» AWS Lambda        | File processing              |
| ğŸ—ƒï¸ DynamoDB        | Processed data storage       |
| ğŸ” IAM              | Permissions & access control |
| ğŸ“Š CloudWatch       | Logs & monitoring            |

---

## ğŸ“ **Lambda Code Summary**

Your Lambda script handles:

* Downloading the object from S3
* Parsing file contents
* Structuring the data
* Writing batches to DynamoDB
* Logging, error handling, and retries

---

## âš™ï¸ **Deployment Steps**

1. Create S3 bucket â†’ enable event notifications
2. Create SQS queue â†’ link with S3 event
3. Create Lambda function â†’ attach SQS trigger
4. Add IAM permissions:

   * `S3:GetObject`
   * `SQS:ReceiveMessage`
   * `DynamoDB:PutItem`
   * `Lambda:Invoke`
5. Deploy the Windows Folder Watcher service
6. Upload sample files â†’ verify pipeline flow

---

## ğŸ§ª **Testing the Pipeline**

âœ”ï¸ Drop a file into the monitored Windows folder
âœ”ï¸ Check S3 raw zone
âœ”ï¸ Confirm SQS receives metadata
âœ”ï¸ Lambda logs show processing steps
âœ”ï¸ DynamoDB table gets new records

---

## ğŸ“¢ **Future Enhancements**

* Add file validation & schema checks
* Support CSV, JSON, XML, Parquet
* Add Athena for analytics
* Create SNS notifications for success metrics
* Implement dead-letter queue for failures

---

## ğŸ™Œ **Contributors**

ğŸ‘¤ **Gnana Prakash N**
* Data Engineer | AWS | Python | Spark | Automation*

